{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ecbee34-52fa-40c4-b770-7cf572c68b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in /opt/conda/lib/python3.11/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c34c86fa-4eb5-469a-b262-000f0d00abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import random\n",
    "import time\n",
    "\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "\n",
    "KAFKA_SERVERS = ['kafka1:9092', 'kafka2:9092', 'kafka3:9092']\n",
    "\n",
    "class HPCKafkaProducer(KafkaProducer):\n",
    "    \"\"\"See API docs for further information:\n",
    "    \n",
    "    https://kafka-python.readthedocs.io/en/master\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.sent_msg_counter = 0\n",
    "    \n",
    "    def send_dummy_messages(self, number_of_msgs, topic=\"hpcDummyTopic\"):\n",
    "        \"\"\"Send number_of_msgs messages containing an increasing ID\"\"\"\n",
    "        for _i in range(number_of_msgs):\n",
    "            self.send(topic, bytes(f\"Message {self.sent_msg_counter} at {time.time()}\", encoding='utf-8'))\n",
    "            self.sent_msg_counter += 1\n",
    "        self.flush()\n",
    "        print(f\"{number_of_msgs} messages published successfully.\")\n",
    "\n",
    "producer = HPCKafkaProducer(bootstrap_servers=KAFKA_SERVERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81af3ec3-3458-41e8-8a81-8383fad39cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPCKafkaConsumer(KafkaConsumer):\n",
    "    \"\"\"See API docs for further information:\n",
    "    \n",
    "    https://kafka-python.readthedocs.io/en/master\n",
    "    \"\"\"\n",
    "    def receive_n_messages(self, number_of_msgs, topic=\"hpcDummyTopic\"):\n",
    "        \"\"\"Receive number_of_msgs messages\"\"\"\n",
    "        for i, msg in enumerate(self):\n",
    "            if i == 0:\n",
    "                print(f\"First message printed full:\\n{msg}\\n\")\n",
    "            else:\n",
    "                print(msg.value)\n",
    "            if i >= number_of_msgs - 1:\n",
    "                break\n",
    "\n",
    "consumer = HPCKafkaConsumer(\"hpcDummyTopic\", bootstrap_servers=KAFKA_SERVERS, auto_offset_reset='earliest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d4bf8c-723b-4f34-b4b7-e19ba6093109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 messages published successfully.\n",
      "First message printed full:\n",
      "ConsumerRecord(topic='hpcDummyTopic', partition=0, offset=0, timestamp=1695192984884, timestamp_type=0, key=None, value=b'Message 10 at 1695192984.8845954', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=32, serialized_header_size=-1)\n",
      "\n",
      "b'Message 11 at 1695192984.8849473'\n",
      "b'Message 12 at 1695192984.8849945'\n",
      "b'Message 13 at 1695192984.8850214'\n",
      "b'Message 14 at 1695192984.8850446'\n",
      "b'Message 15 at 1695192984.885067'\n",
      "b'Message 16 at 1695192984.885089'\n",
      "b'Message 17 at 1695192984.8851097'\n",
      "b'Message 18 at 1695192984.8851311'\n",
      "b'Message 19 at 1695192984.8851533'\n"
     ]
    }
   ],
   "source": [
    "# This should be running in different notebooks/docker containers\n",
    "producer.send_dummy_messages(10)\n",
    "time.sleep(1)\n",
    "consumer.receive_n_messages(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d648170-e751-4d07-8496-2c0309559005",
   "metadata": {},
   "source": [
    "### Creation of topics\n",
    "The first message will create a new topic automatically with its default settings. You can also create topics with different settings your own, e.g. using the following command:\n",
    "\n",
    "```docker exec -ti kafka1 /usr/bin/kafka-topics --create  --bootstrap-server kafka1:9092,kafka2:9092,kafka3:9092 --replication-factor 2 --partitions 4 --topic topic1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5a81d-0eca-4660-8dfb-57d902a69441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
